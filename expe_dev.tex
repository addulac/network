\documentclass[a4paper, 12pt]{article}

%\usepackage[cmex10]{amsmath, mathtools}
\usepackage{amsmath,amssymb,amsbsy,amsfonts,amsthm}
\usepackage{multirow}
\usepackage{bm}
\usepackage{enumerate}
\usepackage{url}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{fancyvrb}
\usepackage{yfonts}
\usepackage{dsfont}
\usepackage{calc} %    For the \widthof macro
\usepackage{xparse} %  For \NewDocumentCommand
\usepackage{wrapfig}
\usepackage{tikz}
\usepackage{lipsum}
%\input{../tikz.conf}

\usepackage{graphicx}
\usepackage{subcaption}

\usetikzlibrary{bayesnet}

%%%%%%%%%%%%%%%%%%%%
%%% Goemetry
%%%%%%%%%%%%%%%%%%%%
%\usepackage[margin=0.25in]{geometry}
\usepackage{geometry}
\geometry{
    a4paper,
 total={420pt,700pt},
 %left=20mm,
 top=20mm,
 }


\title{Networks Properties -- Experiments}

\begin{document}

\maketitle
\tableofcontents

To illustrate our theoretical results, we evaluate the predictive performance and the ability of the models to capture homophily and preferential attachment on artificial and real networks. In the sequel, we first describe the measures used to evaluate the properties of interest and the predictive performance, then the datasets used in our experiments. Then, we detail the evaluation protocol and we present the experimental results.

\section{pymake software}
All our experiments were realized with a frameworks that we developed, and open sourced, available at : https://github.com/dtrckd/pymake. This repository is in current active development in order ot populate Bayesian modelisation, and to do reproducible research. The framework currently contains Gibbs sampler for the MMSB and IBP, for parametric and nonparametric versions. The frameworks also aims helping the design of experiments, the use of available datasets online and working scientific library such as \emph{numpy} \footnote{http://www.numpy.org/}, \emph{scikit-learn} \footnote{http://scikit-learn.org/}, \emph{networkx} \footnote{https://networkx.github.io/} and others.

\section{Evaluation Measures}
This article focus on two properties of networks, namely the preferential attachment effect and the homophily. In this section, we present the measures used in our experiments in order to characterized these properties and to evaluate the predictive performance of the models.

\subsection{Measures for the properties}

\subsubsection{Burstiness}
\label{sec:experiments-burst}

The measures considered to evaluate the preferential attachment rely on a goodness of fit. Indeed, it has been reported that preferential attachment leads to networks characterized by a degree distribution with heavy tail \textbf{ref?}. A typical form of such law, often meet in data, is a a power law distribution. The comparison of the degree distribution in the log-log scale with a linear function gives us a qualitative measure for the preferential attachment. To obtain a second evaluation of the power law hypothesis for the degree distribution, we rely on a  goodness a fit based on a Kolmogorov-Smirnov (KS) test. We follow the protocol described in \cite{clauset2009power} which consists of the following steps:
\begin{itemize}
	\item Estimate the parameters $x_\text{min}$ and $\alpha$ of the power law model. Nevertheless, in order to provide a comparable measure of different degrees distributions, as it is the case in our experimentations, we choose to fix $x_\text{min}$  to the smallest value observed in the degree distribution evaluated.
	\item Calculate the goodness of fit on the data sample (typically the degree of a networks). The resulting $p$-value gives an estimate of the  plausibility of the hypothesis for the data. The p-value is actually the ratio of the number of the time where a kolmogorov-Smirnov test statistics, evaluated on samples generated by the power law, is higher than the KS test statistics on the data samples. 
    \item the number of times $S$ where the KS statistics is compared is chosen, following \cite{clauset2009power}, with a precision of $\epsilon = 3^{-2}$. The  number of loops is then $S = \frac{1}{4}\epsilon^{-2}$.
\end{itemize}

If p is large (close to 1), then the difference between the data and the model can be attributed to statistical fluctuations alone; if it is small, the model is not a plausible fit for the data and we can not conclude that there is an evidence for the preferential attachment in the network. However, as mentioned in \cite{clauset2009power} high value of the $p$-value should be considered with caution for at least two reasons. First, there may be other distribution that match the data equally or better. Second, a small number of samples of the data may lead to high p-value and reflect the fact that is hard to rule out a hypothesis in such a case.



\paragraph{Local burstiness : }
In the context of latent models, while there is no ambiguity in computing the overall degree distribution, it is less obvious for the local case. We explain here the computation of the local degree distribution for each models according to section \ref{sec:burstiness} :
\begin{itemize}
        \item for IMMSB, each network has an associated membership tensor $Z$, that indicates the membership of nodes for each  interactions. In order to draw the local degree distribution for a block $c$, we reduce the adjacency matrix in order to retain only the links that occurs inside a block $c$. The local degree distribution is thus computed on the reduce adjacency matrix defines as follows $Y^c =\{ y_{ij}^c=1 \ \textrm{if}\ y_{ij}=1 , z_{i\rightarrow j}=c, z_{i\leftarrow j}=c\}$.
        \item for ILFM, each node is associated with a fix feature vector; the local degree distribution for the block $c$ is obtain by taking only the contribution of the features $c$ on the adjacency matrix. Thus, the local degree degree distribution is computed on the reduce adjacency matrix defined by $Y^c =\{ y_{ij}^c=1 \ \textrm{if}\ y_{ij}=1 , f_{ic}=1, f_{jc}=1\}$
\end{itemize}

\subsubsection{Homophily}

For the homophily property, defined in section \ref{sec:homophily}, we rely on two different measures:

\begin{itemize}
    \item  Pearson' correlation coefficient between the probability of having a link $P(y_{ij}=1),  i, j \in E^2 $, and the  \textbf{latent / natural ?} similarity $(s_{ij})$ for all pairs of vertices. 
    \item  Means and standard deviations of the similarity computed respectively on the linked and non-linked pairs of nodes.
\end{itemize}

\subsection{Prediction Performance}
The prediction problem is equivalent to a binary prediction problem in two classes since it consists to decide for each pair of nodes if there is an edge or not between them. 
Thus, the performance of the models can be evaluated with usual measures:

\begin{itemize}

\item Precision/Recall/$F_1$ :  The local precision, recall and $F_1$ scores concern the links predicted as an edge.  The global (precision), denoted global in the tables, refers to the accuracy of the model. 
\textit{mettre ailleurs} Note that each group of row is indexed by  a number $K$ which indicates various values of initialization of the latent feature dimension.
\item AUC-ROC : Receiver operating characteristic curves allow also to graphically compare the  models on each dataset.
\end{itemize}

\section{Training Datasets}

In our experiments, we consider four artificial networks and four real networks. We described in the following those networks, and show a summary of properties in table \ref{table:networks_measures}.


\begin{table}[h] 
	\centering
	\caption{Networks standard measure on datasets.}
	%\resizebox{\textwidth}{!}{  
		\begin{tabular}{lcrrrrcr}
			\hline
			Networks     & Nodes & edges & density    \\
			\hline
			Network1          & 1000  & 6014  & 0.007 \\
			Network2          & 1000  & 5000  & 0.006 \\
			Network3          & 1000  & 11000 & 0.01  \\
			Network4          & 1000  & 61000 & 0.06   \\
			manufacturing     & 167  & 5950   & 0.24  \\
			UC Irvine         & 1899 & 22195  & 0.08  \\
			\hline
		\end{tabular}
%	}
	\label{table:networks_measures}
\end{table}



\subsection{Artificial networks}

The artificial networks have been generated with DANC-Generator \cite{largeron2015}. This generator has been chosen because it allows to build an attributed graph having a community structure  and  the known properties of real-world networks such as preferential attachment and homophily.
Moreover, by modifying the parameters, these properties can be weakened. Finally, DANC-Generator is available under the terms of the GNU Public License and the parameters can be shared for experiments reproducibility.

Four artificial networks (Network1, ..., Network4) have been generated. Their adjacency matrices and global degree distributions are presented in Figure \ref{fig:synt_graph}. Table \ref{table:synt_graph} gives the results of the KS test: $p$-value, values estimated for the parameters  $\alpha$ and $x_\text{min}$,  and $n_{tail}$ \textbf{ntail ?}. For each network, Figure \ref{fig:synt_graph_local} represents the local degree distribution associated to each \emph{ground truth} community and Table \ref{table:synt_graph_local} reports the KS results in the local case. The inner degree distribution (edges inside a community) and outer degree distribution (edges between community) are plotted separately.

Each network presents a different affinity to preferential attachment and homophily.
Indeed, As shown Figure \ref{fig:synt_graph}, Network1 and Network2, and to a lesser extend, Network3 verify preferential attachment whereas it is not the case for the Network3. The results of the KS test in Table \ref{table:synt_graph} confirm this analysis since the $p$-value is very high for network 1 and 2. The $p$-value decrease for network3 until a null value for network4.
Concerning the local preferential attachment, that can be evaluated on these artificial networks where the ground truth communities are provided by the generator, and reported in Figure \ref{fig:synt_graph_local} and the Table \ref{table:synt_graph_local}. It shows a tendency to the properties for being strongly represented in the two first networks and in a lesser extend for the two last. This is particularly visible on high variance on the $p$-value for network 3 and 4, where the properties vary among classes.

\input{t/a.tex}
\input{t/b.tex}

\begin{table}[h]
\caption{Power law goodness of fit results for characterization of global preferential attachment in synthetic networks.}
\centering
    \begin{tabular}{lrrrr}
    \hline
               &   pvalue &   alpha &   x\_min &   n\_tail \\
    \hline
     Network1 &    1.000 &   2.424 &       3 & 1000.000 \\
     Network2 &    0.971 &   2.897 &       3 & 1000.000 \\
     Network3 &    0.798 &   1.758 &       3 & 1000.000 \\
     Network4 &    0.000 &   1.354 &       3 & 1000.000 \\
    \hline
    \end{tabular}
\label{table:synt_graph}
\end{table}

\begin{table}[h]
\caption{Power law goodness of fit results for characterization of local preferential attachment in synthetic networks.}
\centering
    \begin{tabular}{lllll}
    \hline
    & pvalue          & alpha           & x\_min        & n\_tail           \\
    \hline
    Network1 & 0.9 $\pm$ 0.07  & 2.7 $\pm$ 0.1 & 1.8 $\pm$ 0.9 & 154.4 $\pm$ 83.9 \\
    Network2 & 0.9 $\pm$ 0.008 & 3.0 $\pm$ 1.2  & 1.8 $\pm$ 0.9 & 170.9 $\pm$ 66.4  \\
    Network3 & 0.8 $\pm$ 0.26 & 7.0 $\pm$ 5.8 & 1.8 $\pm$ 0.9 & 136.3 $\pm$ 94.0 \\
    Network4 & 0.6 $\pm$ 0.49    & 1.5 $\pm$ 0.1 & 1.8 $\pm$ 0.9 & 204.7 $\pm$ 53.0 \\
    \hline
    \end{tabular}
\label{table:synt_graph_local}
\end{table}

\subsection{Real networks}

We evaluate also the models on two real networks.
The first one, denoted UC Irvine \footnote{available at:}, is built from a online community of 1899 students from the University of California. Each node corresponds to a user and a   directed edge represents a sent message.
The second one, denoted Manufacturing \footnote{available at:}, is an internal email communication network between employees of a mid-sized manufacturing company. Each vertex is associated  to an employee and an oriented link represents like previously a sent email.

The adjacency matrices and global degree distributions are presented in Figure \ref{fig:real_graph}. The goodness of fit based on the KS test, used as a reference for the global preferential attachment effect, is reported in Table \ref{table:real_graph}. According to Figure \ref{fig:real_graph} as well as Table \ref{table:real_graph}, it appears that the preferential attachment property is verified in Manufacturing and not in UC Irvine.

\input{t/c.tex}

\begin{table}
\caption{Power law goodness of fit results for characterization of global degree attachment in real networks.}
\centering
\begin{tabular}{lrrrr}
   &   pvalue &   alpha &   x\_min &   n\_tail \\
\hline
 Manufacturing &    0.000 &   1.434 &       3 &  167.000 \\
 UC Irvine     &    0.989 &   1.787 &       3 & 1899.000 \\
\hline
\end{tabular}
\label{table:real_graph}
\end{table}



\section{$M_e$ -- Model fitted}

For each datasets described earlier, we run a MCMC inference consisting of 200 iterations to learn the posterior distribution of each the IMMSB model and ILFM, described in section \ref{sec:models}. For IMMSB, concentration parameters of HDP were optimized following \cite{HDP} using vague gamma priors $\alpha_0 \sim \text{Gamma}(1,1)$ and $\gamma \sim \text{Gamma}(1,1)$. The parameter for the matrix weights were fixed to $\lambda_0=\lambda_1=0.1$. For ILFM, the IBP hyper-parameter was fixed to $\alpha=0.5$ and the weights hyper-parameter to $\sigma_w = 1$. 

The inference procedure was run under this settings in all of the 4 synthetic datasets and 2 real networks.

All our experimental platform is available online \footnote{https://github.com/dtrckd/pymake}. It is an ongoing development in order to provide a flexible way to design and run experiments and make data analysis.

\subsection{Burstiness}

In order to measure the different level of burstiness we used the models to generate full networks. (The procedure for such measure is similar than those explain in the section \ref{sec:mgmg}. Thus given the model parameters $\mathcal{M}_e = \{F ,\Phi\}$, we generate a set of 20 networks. In the next, results are averaged  with standard deviation for all those generated networks.

% Global
In figure \ref{fig:me_fit_gburst_mmsb} and \ref{fig:me_fit_gburst_ibp}, we report the global degree for generated networks for respectively IMMSB and ILFM. In Table \ref{table:global_gof}, we report the corresponding goodness of fit evaluation.


\input{t/me_fit_gburst_mmsb}
\input{t/me_fit_gburst_ibp}

\begin{table}
    \caption{Power law Goodness of fit for the global preferential attachment effect.}
\centering
    \begin{tabular}{lllll}
    \hline
        \textbf{IMMSB} & pvalue          & alpha           & x\_min          & n\_tail           \\
    \hline
    Network1     & 0.907 $\pm$ 0.11 & 1.396 $\pm$ 0.004 & 1.0 $\pm$ 0.0    & 990.1 $\pm$ 3.1  \\
    Network2     & 1.0 $\pm$ 0.0     & 1.452 $\pm$ 0.005 & 1.0 $\pm$ 0.0    & 974.4 $\pm$ 4.9  \\
    Network3     & 0.0 $\pm$ 0.0     & 1.294 $\pm$ 0.001 & 1.0 $\pm$ 0.0    & 999.0 $\pm$ 0.9 \\
    Network4     & 0.0 $\pm$ 0.0     & 1.203 $\pm$ 0.025 & 1.25 $\pm$ 0.5 & 999.1 $\pm$ 0.7 \\
    Manufacturing & 0.006 $\pm$ 0.01 & 1.244 $\pm$ 0.002 & 1.0 $\pm$ 0.0    & 165.3 $\pm$ 1.3 \\
    UC Irvine     & 1.0 $\pm$ 0.0     & 1.348 $\pm$ 0.002 & 1.0 $\pm$ 0.0    & 1852.7 $\pm$ 5.7 \\
    \hline
    \end{tabular}

    \begin{tabular}{lllll}
    \hline
        \textbf{ILFM} & pvalue          & alpha           & x\_min       & n\_tail           \\
    \hline
    Network1     & 1.0 $\pm$ 0.0     & 1.4 $\pm$ 0.003 & 1.0 $\pm$ 0.0 & 919.5 $\pm$ 5.9 \\
    Network2     & 1.0 $\pm$ 0.0     & 1.4 $\pm$ 0.004 & 1.0 $\pm$ 0.0 & 893.7 $\pm$ 7.1  \\
    Network3     & 0.01 $\pm$ 0.02  & 1.3 $\pm$ 0.002 & 1.0 $\pm$ 0.0 & 982.7 $\pm$ 3.6 \\
    Network4     & 0.0 $\pm$ 0.0     & 1.2 $\pm$ 0.018 & 1.1 $\pm$ 0.3 & 998.4 $\pm$ 0.9 \\
    Manufacturing & 0.018 $\pm$ 0.01 & 1.2 $\pm$ 0.002 & 1.0 $\pm$ 0.0 & 164.2 $\pm$ 1.4 \\
    UC Irvine     & 1.0 $\pm$ 0.0     & 1.3 $\pm$ 0.002 & 1.0 $\pm$ 0.0 & 1798.3 $\pm$ 8.2 \\
    \hline
    \end{tabular}
    \label{table:global_gof}
\end{table}



% Local
In figure \ref{fig:me_fit_lburst_mmsb} and \ref{fig:me_fit_lburst_ibp}, we report the local degree for generated networks for respectively IMMSB and ILFM. In Table \ref{table:local_gof}, we report the corresponding goodness of fit evaluation. \underline{Note that the pvalue reported here, are the averaged of all} classes.


\textcolor{red}{here comment...} ~\\
\textcolor{red}{x\_min could be removed from table, I explains earlier how I choose it.}

\input{t/me_fit_lburst_mmsb}
\input{t/me_fit_lburst_ibp}


\begin{table}
    \caption{Power law Goodness of fit for the local preferential attachment effect.}
\centering
    \begin{tabular}{lllll}                                                                                    
    \hline                                                                
        \textbf{IMMSB}  & pvalue         & alpha           & x\_min          & n\_tail             \\            
    \hline                                                                                                    
    Network1     & 1.0 $\pm$ 0.0    & 7.433 $\pm$ 2.2 & 1.0 $\pm$ 0.0    & 53.737 $\pm$ 9.8   \\
    Network2     & 1.0 $\pm$ 0.0    & 1 $\pm$ 0.0    & 1.0 $\pm$ 0.0    & 41.895 $\pm$ 11.2  \\                             
    Network3     & 1.0 $\pm$ 0.0    & 4.074 $\pm$ 0.7 & 1.0 $\pm$ 0.0    & 112.143 $\pm$ 18.5 \\                
    Network4     & 1.0 $\pm$ 0.0    & 1.957 $\pm$ 0.2 & 1.0 $\pm$ 0.0    & 316.095 $\pm$ 69.5 \\
    Manufacturing & 0.55 $\pm$ 0.5 & 1.242 $\pm$ 1.1 & 0.55 $\pm$ 0.4 & 31.4 $\pm$ 14.644    \\              
    UC Irvine     & 1.0 $\pm$ 0.0    & 5.213 $\pm$ 0.9 & 1.0 $\pm$ 0.0    & 242.0 $\pm$ 26.1   \\                
    \hline                                                                
    \end{tabular}    

    \begin{tabular}{lllll}
    \hline
        \textbf{ILFM} & pvalue          & alpha           & x\_min           & n\_tail              \\
    \hline
    Network1     & 1.0 $\pm$ 0.0     & 1.93 $\pm$ 0.3  & 1.0 $\pm$ 0.0     & 325.7 $\pm$ 154.9 \\
    Network2     & 0.952 $\pm$ 0.2 & 1.76 $\pm$ 0.5 & 0.9 $\pm$ 0.2 & 423.8 $\pm$ 210.1  \\
    Network3     & 0.957 $\pm$ 0.2 & 1.58 $\pm$ 0.3 & 1.0 $\pm$ 0.0     & 587.0 $\pm$ 252.2 \\
    Network4     & 0.698 $\pm$ 0.4 & 1.33 $\pm$ 0.1 & 1.0 $\pm$ 0.0     & 632.9 $\pm$ 200.1  \\
    Manufacturing & 0.69 $\pm$ 0.3   & 1.40 $\pm$ 0.2 & 1.0 $\pm$ 0.0     & 92.0 $\pm$ 26.5     \\
    UC Irvine     & 1.0 $\pm$ 0.0     & 1.87 $\pm$ 0.4   & 1.0 $\pm$ 0.0     & 994.3 $\pm$ 408.8 \\
    \hline
    \end{tabular}
\label{table:local_gof}
\end{table}

\subsubsection{Comments}

\begin{itemize}
    \item global preferential attachment : both IMMSB and ILFM pass the goodness of fit test for networks 1,2 and UC irvine. The 3 other are rejected. This show that the models can fit to strongly bursty networks. When burstiness is less strong, as for network3, we can notice if we consider the tail of the generated distributions, ILFM appears to have straight tail than ILFM.
    \item local preferential attachment : We can see that the fitness for the local degree distributions of IMMSB is strong for every networks except in the lesser extent for Manufacturing. The confident is also relatively high because of a very small variance over the different class, except again for manunufacturing. The instability of Manufacturing is probably due to his small number of nodes. For ILFM, the fitness decrease from network1 to network4. Also, the pvalue has high variance for network 2 to 4 and for manufacturing which is correlated with the decay of the global burstiness.
\end{itemize}

\subsection{Homophily}

%We evaluate in this section the behaviour of homophily of models according to both, the natural and the latent similarity, reported respectively in tables \ref{table:homo_natural} and \ref{table:homo_latent}. Those results are obtained by computing the Pearson correlation coefficient between a random adjacency matrix and a similarity matrix matrix as defined in \ref{sec_homophily} from a model (either IMMSB or ILFM). Each of these coefficient is averaged an basis on 20 networks generated from the fitted models.

%Firstly, we can notice that the results are stable since the standard deviation is not significant for all experiments. Secondly those results illustrate the fact that both models are homophilic under the natural similarity with a positive correlation in all networks,  and not under the latent similarity with a correlation coefficient near to 0 and oscillating between positive and negative value (Note that this last fact depend on the initialization and the seed of the models).

%%%% correlation betewwen edges and similarity
%\begin{table}
%\caption{Correlation between the natural similarity matrix and adjacency matrix for IMMSB and ILFM.}
%\centering
%    \begin{tabular}{lll}
%    \hline
%    & IMMSB   & ILFM  \\
%    \hline
%    Network1     & 0.23 $\pm$ 0.004  & 0.135 $\pm$ 0.001      \\
%    Network2     & 0.225 $\pm$ 0.005 & 0.112 $\pm$ 0.001      \\
%    Network3     & 0.186 $\pm$ 0.002 & 0.165 $\pm$ 0.001      \\
%    Network4     & 0.385 $\pm$ 0.001 & 0.443 $\pm$ 0.0        \\
%    Manufacturing & 0.661 $\pm$ 0.003 & 0.583 $\pm$ 0.002      \\
%    UC Irvine     & 0.21 $\pm$ 0.002  & 0.129 $\pm$ 0.001      \\
%    \hline
%    \end{tabular}
%\label{table:homo_natural}
%\end{table}
%
%
%\begin{table}
%    \caption{Correlation between the latent similarity matrix and adjacency matrix for IMMSB and ILFM.}
%    \begin{tabular}{lll}
%    \hline
%    & ILFM  & IMMSB \\
%    \hline
%    Network1     & 0.021 $\pm$ 0.001  & -0.035 $\pm$ 0.001      \\
%    Network2     & -0.007 $\pm$ 0.001 & -0.051 $\pm$ 0.001      \\
%    Network3     & 0.012 $\pm$ 0.001  & 0.002 $\pm$ 0.001       \\
%    Network4     & 0.141 $\pm$ 0.001  & 0.056 $\pm$ 0.001       \\
%    Manufacturing & 0.11 $\pm$ 0.003   & 0.073 $\pm$ 0.004       \\
%    UC Irvine     & 0.148 $\pm$ 0.002  & -0.063 $\pm$ 0.0        \\
%    \hline
%    \end{tabular}
%\label{table:homo_latent}
%\end{table}


We evaluate in this section the behaviour of homophily of models according to both, the natural and the latent similarity.

In table \ref{table:homo_pearson} we compute the Pearson correlation for the homophily measure. Note that this coefficient for the natural similarity is always equal to one.

In table \ref{table:homo_natural} and \ref{table:homo_latent} we compute contingency tables for homophily.
\textcolor{red}{ces deux tablueaux sont horrible a formater. Je les laisse tel quel pour le moemnt que tu vois les valeurs, masi je ne pense que ce soit la mesure Ã  retenir. A la rigueur un average sur tout les network de cess valeurs...}

\input{t/table_homo_natural}
\input{t/table_homo_latent}

\begin{table}[h]
    \caption{Correlation between the latent similarity matrix and the predictive likelihood for IMMSB and ILFM.}
    \centering
    \begin{tabular}{lll}
    \hline
    & IMMSB  & ILFM \\
    \hline
    Network 1     & 0.082 &  -0.126   \\
    Network 2     & 0.001     &  -0.116   \\
    Network 3     & 0.114     &  0.123    \\
    Network 4     & 0.076     &  0.009    \\
    Manufacturing & 0.384     &  -0.011   \\
    UC Irvine     & 0.286     &  -0.213   \\
    \hline
    \end{tabular}
    \label{table:homo_pearson}
\end{table}


\subsubsection{Comments}
\begin{itemize}
    \item The measure of the natural similarity over links and non links satisfy the homophily effect for IMMSB and ILFM (table \ref{table:homo_natural_ibp} and \ref{table:homo_latent_immsb}). In the contrary there is no evidence for a correlation between the latent similarity and the link likelihood (table \ref{table:homo_pearson}). 
\end{itemize}


\subsection{Prediction Performance}
In order to evaluate the  prediction performance of the models, we build a training set and a testing set from the original datasets. In order to achieve this, we generate a random mask consisting of 20 percent of the size of the adjacency matrix. This mask is used a our testing set, while the 80 remaining percent are used as a training set. The results for the prediction evaluation are reported in i) the AUC-ROC measures in figure \ref{fig:auc}, and ii) in the precision/recall results in table \ref{table:unbalanced}.
Each prediction results were averaged on 10 repetitions, and results were found to be stable regarding on the random  initialization and the stochastic optimization procedure. 

\input{t/table_results}

\input{t/auc}

\subsubsection{Comments}

\begin{itemize}
\item comparing the performance between both models in the links prediction precision and recall and $F_1$ measure (ref{table:unbalanced}), can seem to conflict with results in the ROC curve (\ref{fig:auc}). More precisely we see that ILFM dominate IMMSB on the $f_1$ measures on all experiments except for one (network 1, K=15). But on the AUC-ROC analysis( \ref{fig:auc}) we see that IMMSB dominate ILFM for two networks (Networks 1 and Networks 2), although it's number of latent feature is almost half lesser than for ILFM. This behavior is also reflected on the accuracy for both models (global precision); The accuracy of IMMSB models is higher for the Network1 and Network2, and this is the opposite for ILFM, which are more accurate for Network3 and Network4. Interestingly, we see that for ILFM, the dimension of the latent feature for which ILFM converged, for the two first networks is significantly higher than the two other. In other words the ILFM model seems to compensate is weak performance by increasing the number of features.
 
\end{itemize}

%\section{$M_e$ -- Model Generated}


\bibliographystyle{unsrt}
\bibliography{./a}

\end{document}
