\section{Introduction}
\label{sec:introduction}
Although drawn from a wide range of domains, most real world networks exhibit common properties, such as a community structure, homophily or,  bustiness related to  preferential attachment (\cite{Newman2010, Barabasi2003}).

In parallel, recent years have seen powerful relational learning models enable implementing algorithms to solve the  problem commonly known as link prediction which consists in predicting the likelihood of a future association between two nodes in the network (\cite{Liben-Nowell07, HassanZaki11}). Among the methods that have proven their efficiency to handle this task, one can mentioned the probabilistic approaches which model the joint probability among the vertices in the network by Bayesian graphical models. In this article, we consider more particularly two types of models belonging to this family: the latent feature model [meeds] and the mixed-membership stochastic block model [Airoldi] and, to be as general as possible, their non-parametric extensions, respectively based on the Indian Buffet Process (IBP) and the Hierarchical Dirichlet Process(HDP).
 
%\textbf{blbla sur LFRM et sur MMSBM}. 
Our aim is to study the ability of these models to capture two properties commonly observed in real networks: homophily and preferential attachment.
Homophily is the tendency of people to associate with others having the same characteristics (genre, age \textit{etc.}).  Consequently, when this property is verified in a network,  vertices are more likely to be connected when they are similar than when they are different  with regard to their attribute values \cite{mcpherson2001birds}.  %We can noticed that homophily is related to assortativity, that is more general since it refers to the tendency to be be linked to others similar in some way.
Furthermore,  preferential attachment, sometimes referred as \textit{rich get richer } rule,  is a mechanism  according to which new nodes prefer to join the more connected nodes existing in the network. Thus, each node is connected to an existing node with a probability proportional to
the number of links of the chosen node. However, as noted in Leskovec \textit{et al.}, usually in social networks, the entities do not have a global knowledge of the network. Consequently, the preferential attachment model is more likely to be local, in other words,  a vertex is more likely to create connections with vertices having a high degree and which are close in the graph \cite{LeskovecBKT08}.


In section \label{sec:models}, we present the ILFM model and the IMMSB model in an unified framework which allows to understand their behavior and to compare them. This framework provides notably a better interpretation of the contraints underlying the models regarding the properties of interest. 
 Then, in sections  \ref{sec:homophily} and \ref{sec:burstiness}, we introduce formal definitions of these properties
within the Bayesian framework, and we study how each model
is able to capture this property. We theoretically demonstrate that ILFM is strongly homophilic whereas IMMSB is only weakly homophilic. We show also that ILFM is neutral with respect to global
and local preferential attachment whereas \textbf{IMMSB satisfies the burstiness effect}.  Finally, in section \ref{sec:experiments}, with the purpose to illustrate these theoretical results, we present experiments carried out on real and artificial datasets which confirm the  learning ability of the models on different networks having more or less the properties. Finally, section \ref{sec:concl} concludes this article and gives avenues for future
work. The notations and the mathematical background required in the sequel are briefly recalled in the next section.
 
% Ex intro Adrien

% We provide formal definitions of fundamental properties of social networks which are design to be consistent with the probabilistic framework. We study those properties on two general models based on Bayesian nonparametric prior namely the Hierarchical Dirichlet Process (HDP) and the Indian Buffet Process (IBP). We show the relation between those properties and the models. Thus it provides a better comprehension of the models and their limitation in order to capture those properties in a learning problem. Additionally, we propose an adaptation of priors which gives a better interpretation of models in terms of assumptions on social networks and lead to better prediction performance.

% Recently, several complex Bayesian models based on latent variables to explain the structure of social networks have been introduced [mmsb, ilfrm, etc]. This work was mainly evaluated on prediction tasks, such as link prediction or communities detection. However, few works have been done concerning the study of the intrinsic capacity of the models to model basic properties that arise in social networks, such as the dynamics of degree distribution, known to exhibit the preferential attachment effect [barabasi, web..] or the homophily effect[ref].
% For exemple, the heavily study Latent Dirichlet Allocation Model LDA model, being a particular of Mixed Membership Stochastic Blockmodel (MMSB) for networks, made no epistomological claim about the conjugacy used. In this work we found that conjugacy played a role in the ability of the model to capture some properties.
% ~\\


% (++ Indeed the most heavily studied properties in social networks was the degree distribution and the mixing pattern (homophily/assortativity) tableaux !)

% (++ not clear consensus of the formalism of properties and their evaluation, and whatsoever for the homophily property, the feature the definition are usually for single attribute... We consider a general vector . (with a measure working for both latent and real features)

% (++ Probabilistic models we are interested in provide two ways of representing the data or network. One fall in the paradigm of mixture models and the other in the latent feature modeling. A motivation of those two modeling paradigm is that they are consistent with two key nonparametric prior for discrete data, namely the Dirichlet process (DP) and the the Indian Buffet Process (IBP). Many baysian model can be view as equivalent to truncated models with nonparametric priors. This provide a motivation to study those models. Furthermore, they are used as priors to generate latent features, either as proposition vector (class/DP) or binary vector (feature/IBP). It is admitted that those priors gives bursty features [accounting for burstiness in topic model]. We seek to clarify why this is true and how the burstiness can propagate at the degree level.~\\


% In the next section we will, first, explain the mathematical background in a machine learning context. Secondly, we will review the models of interest for dyadic data. Then, we will introduce the formal definition of properties of interest in social networks within the Bayesian frameworks, and how this is translated in terms of assumptions within Bayesian priors. Finally, we will show empirical results (on synthetic and real datasets) to support our claims.~\\

%Study the poisson binomial distribution for the out links of a node. This is the degree distribution and should be bursty to have community in networks.



